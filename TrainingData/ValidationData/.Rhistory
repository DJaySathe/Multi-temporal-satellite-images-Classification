plot(twoD)
plot(density(twoD)
;
plot(density(twoD))
plot(density(twoD1))
plot(density(twoD2))
plot(density(totalData))
plot(totalData,col='red',xlim=c(0,80),ylim=c(0,70))
checkvalidity<-function(result,k){
print(k)
for (i in 1:k) {
print(i)
clusterframe <- data.frame(result$cluster)
opdata <- cbind(trialdata,clusterframe)
normtestdata <- opdata[which(opdata[,'result.cluster']==i),- length(opdata)]
normtestdata <- data.matrix(normtestdata)
normtest.result <- ad.test(normtestdata) #only need a valid normalality test
print(normtest.result$p.value)
if(normtest.result$p.value<=0.0001)
{
return(FALSE)
}
else{
print('valid cluster')
}
}
}
needtoinc = FALSE
library(nortest)
#trialdata <- data.frame(iris$Petal.Length,iris$Petal.Width)
trialdata <- iris[,-length(iris)]
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==10){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
needtoinc = FALSE
library(nortest)
#trialdata <- data.frame(iris$Petal.Length,iris$Petal.Width)
#trialdata <- iris[,-length(iris)]
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==10){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
totalData
trialdata <- totalData
class(trialdata)
trialdata <- data.frame(trialdata)
class(trialdata)
needtoinc = FALSE
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==10){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==100){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
library(ISLR)
default = Default
View(default)
write.csv(default)
write.csv(default,"C:/Users/Sanket Shahane/Desktop/Default.csv")
library(bnlearn)
csvdata<-read.csv('C:/Users/Sanket Shahane/Google Drive/MS/FDS/Homework/HW5/HW45R/bn-data.csv')
head(csvdata)
csvd1 <- csvdata[,-1]
bn.hs <- hc(csvd1)
plot(bn.hs)
fitted <- bn.fit(bn.hs,csvd1)
fitted$Smoking
fitted$Family
fitted$P..Work
fitted$M..Work
fitted$Proteins
fitted$Pressure
library(e1071)
data(HousVotes84)
data(HouseVotes84)
HouseVotes84
library(mlbench)
HouseVote84
data("HouseVotes84")
dataset <- HouseVotes84
fix(dataset)
HouseVotes84?
;;
?HouseVotes84
model <- naiveBayes(Class ~ ., data = HouseVotes84)
predict(model, HouseVotes84[1:10,-1])
predict(model, HouseVotes84[1:10,-1], type = "raw")
table(pred, HouseVotes84$Class)
pred <- predict(model, HouseVotes84[,-1])
table(pred, HouseVotes84$Class)
head(dataset)
head(dataset[,c(1,12)])
head(dataset[,c(1,12)],50)
head(dataset[which(dataset$Class=="republican"),c(1,12)],50)
sum(dataset[which(dataset$Class=="republican"),c(1,12)],50)
length(dataset[which(dataset$Class=="republican"),c(1,12)],50)
length(dataset[which(dataset$Class=="republican"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican"),c(1,12)],50)
nrow(dataset[which(dataset$Class=="republican"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" && dataset$V11=="y"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" && dataset$V11=="n"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" and dataset$V11=="n"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" & dataset$V11=="n"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" & dataset$V11=="y"),c(1,12)])
dataset[which(dataset$Class == "republiccan" & is.na(dataset$V11)),c(1,12)]
dataset[which(dataset$Class == "republiccan" & dataset$V11 == N/Q),c(1,12)]
dataset[which(dataset$Class == "republiccan" & dataset$V11 == NA),c(1,12)]
dataset[which(dataset$Class == "republican" & dataset$V11 == NA),c(1,12)]
dataset[which(dataset$Class == "republican" & is.na(dataset$V11)),c(1,12)]
model = naiveBayes(Class~.,data=dataset)
model
predict(model, HouseVotes84[1:10,-1])
table(predict(model, HouseVotes84[1:10,-1]),HouseVotes84$Class)
table(predict(model, HouseVotes84[1:10,-1]),HouseVotes84$Class[1:10])
pred <- predict(model, HouseVotes84[,-1])
table(pred, HouseVotes84$Class)
mean(pred==HouseVotes84$Class)
?sample()
set.seed(100)
sample(dataset,)
0.8*nrow(dataset)
training<-sample(dataset,0.8*nrow(dataset))
training<-sample(dataset,0.2*nrow(dataset))
training<-sample(dataset[,],0.2*nrow(dataset))
sample(dataset, size=0.8*nrow(dataset), replace = FALSE, prob = NULL)
trainingdata<-dataset[sample(nrow(dataset), size=0.8*nrow(dataset), replace = FALSE, prob = NULL)]
trainingdata<-dataset[sample(nrow(dataset), size=0.8*nrow(dataset), replace = FALSE, prob = NULL),]
testdata = dataset[-trainingdata,]
testdata = dataset[,] - trainingdata[,]
sample(dataset, size=0.8*nrow(dataset), replace = FALSE, prob = NULL)
arr <- sample(nrow(dataset), size=0.8*nrow(dataset), replace = FALSE, prob = NULL)
arr
trainingdata <- dataset[arr,]
testdata <- dataset[-arr,]
model <- naiveBayes(Class~.,trainingdata)
pred <- predict(model,testdata[,-1])
pred
table(pred,testdata$Class)
mean(pred==testdata$Class)
model.logistic <- glm(Class~.,family=binomial(link='logit'),data=trainingdata)
summary(model.logistic)
model.logistic <- glm(Class~.,family=binomial(link='logit'),data=trainingdata,control = list(maxit=50))
summary(model.logistic)
pred.training <- predict(model.logistic,trainingdata[,-1])
mean(pred.training,trainingdata$Class)
mean(pred.training,na.omit(trainingdata$Class)
)
mean(pred.training==trainingdata$Class)
mean(pred.training==na.omit(trainingdata$Class))
is.na(pred.training)
pred.training
na.omit(pred.training)
mean(na.omit(pred.training)==na.omit(trainingdata$Class))
dataset.logistic <- na.omit(dataset)
nrow(dataset.logistic)
nrow(dataset)
arr.logistic <- sample(nrow(dataset.logistic),0.8*nrow(dataset.logistic),replace = FALSE)
trainingdata.logistic = dataset.logistic[arr.logistic,]
testdata.logistic = dataset.logistic[-arr.logistic,]
model.logistic <- glm(Class~.,family=binomial(link='logit'),data=trainingdata.logistic,control = list(maxit=50))
pred.training(model.logistic,trainingdata.logistic[,-1])
pred.training <- predict(model.logistic,trainingdata.logistic[,-1])
mean(pred.training,trainingdata.logistic$Class)
mean(pred.training==trainingdata.logistic$Class)
pred.training
pred.training <- predict(model.logistic,trainingdata.logistic[,-1],type = 'response')
predict()
pred.training
pred.training <- ifelse(pred.training > 0.5,1,0)
pred.training
pred.training <- ifelse(pred.training > 0.5,'y','n')
pred.training
mean(pred.training==trainingdata.logistic$Class)
trainingdata.logistic$Class
pred.training <- ifelse(pred.training > 0.5,'democrat','republican')
mean(pred.training==trainingdata.logistic$Class)
pred.training <- predict(model.logistic,trainingdata.logistic[,-1],type = 'response')
pred.training
pred.training <- ifelse(pred.training > 0.5,'democrat','republican')
mean(pred.training==trainingdata.logistic$Class)
pred.training
pred.training <- predict(model.logistic,trainingdata.logistic[,-1],type = 'response')
pred.training <- ifelse(pred.training > 0.5,"republican","democrat")
mean(pred.training==trainingdata.logistic$Class)
fix(pred.training)
pred.training<-data.frame(pred.training)
fix(pred.training)
fix(trainingdata.logistic$Class)
fix(trainingdata.logistic)
pred.training
trainingdata.logistic$Class
pred.training$pred.training
pred.training$pred.training==trainingdata.logistic$Class
q()
setwd("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData")
dataset = read.csv("finaldata-2015-04-19.csv")
head(dataset)
library(e1071)
?naiveBayes()
View(dataset)
228*0.2
228*0.8
182*0.8
nrow(dataset)
accuracyTestData = sample(nrow(dataset),nrow(dataset)*0.2)
accuracyTestData
accuracyDataVector = sample(nrow(dataset),nrow(dataset)*0.2)
accuracyTestData = dataset[accuracyDataVector,]
df = dataset[-accuracyDataVector,]
write.csv(df,file = "ValidationData-2015-04-19.csv")
write.csv(accuracyTestData,file = "AccuracyData-2015-04-19.csv")
dataset = read.csv("finaldata-2015-12-31.csv")
accuracyTestData = dataset[accuracyDataVector,]
df = dataset[-accuracyDataVector,]
nrow(accuracyTestData)
nrow(df)
write.csv(accuracyTestData,file = "AccuracyData-2015-12-31.csv")
write.csv(df,file = "ValidationData-2015-12-31.csv")
dataset = read.csv("finaldata-2016-01-16.csv")
accuracyTestData = dataset[accuracyDataVector,]
df = dataset[-accuracyDataVector,]
write.csv(df,file = "ValidationData-2015-12-31.csv")
write.csv(accuracyTestData,file = "AccuracyData-2016-01-06.csv")
write.csv(df,file = "ValidationData-2016-01-16.csv")
dataset = read.csv("finaldata-2015-12-31.csv")
df = dataset[-accuracyDataVector,]
write.csv(df,file = "ValidationData-2015-12-31.csv")
dataset = read.csv("finaldata-2016-03-20.csv")
accuracyTestData = dataset[accuracyDataVector,]
df = dataset[-accuracyDataVector,]
write.csv(df,file = "ValidationData-2016-03-20.csv")
write.csv(accuracyTestData,file = "AccuracyData-2016-03-20.csv")
rm(list=ls())
setwd("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/ValidationData")
dataset = read.csv("ValidationData-2015-04-19.csv")
dataset = dataset[-1,]
testVector <- sample(nrow(dataset),nrow(dataset)*0.2)
testData <- dataset[testVector,]
trainData <- dataset[-testVector,]
testData
testData[1]
dataset
head(dataset)
dataset = read.csv("ValidationData-2015-04-19.csv")
dataset = dataset[,-1]
testVector <- sample(nrow(dataset),nrow(dataset)*0.2)
testData <- dataset[testVector,]
trainData <- dataset[-testVector,]
head(trainData)
head(testData)
testData[,0]
testData[,1]
trainData[1,]
trainData[1,1]
trainData[,1]
trainData[0,1]
attach(dataset)
Ultra_Blue
detach(dataset)
attach(trainData)
library(e1071)
colnames(trainData)
model = naiveBayes(Class~Ultra_Blue+Blue+Green+Red+NIR+SWNIR_1+SWNIR_2+Cirrus,data = trainData)
model
prediction = predict(model,testData[,-c(1,2,3)])
prediction
prediction = predict(model,testData[,-c(1,2,3)],type="raw")
prediction
table(predict(m, testData[,-c(1,2,3)]), testData[,3])
table(predict(model, testData[,-c(1,2,3)]), testData[,3])
testData[,-c(1,2,3)]
head(trainData)
trainData = trainData[,-c(1,2)]
head(trainData)
head(testData)
testData = testData[,-c(1,2)]
head(testData)
rownames(testData)
rownames(testData) = NULL
head(testData)
rownames(trainData) = NULL
testData
head(testData)
head(trainData)
detach(trainData)
model = naiveBayes(trainData$Class~.,data=trainData)
model
predict(model,testData[,-1])
head(trainData)
classFrame = trainData[,1]
trainData = trainData[,-1]
cbind(trainData,classFrame)
classFrame = testData[,1]
testData = testData[,-1]
cbind(testData,classFrame)
rownames(testData)
colnames(testData)
head(trainData)
testData <- dataset[testVector,]
trainData <- dataset[-testVector,]
testData = testData[,-c(1,2)]
trainData = trainData[,-c(1,2)]
head(testData)
rownames(testData) = NULL
rownames(trainData) = NULL
head(testData)
head(trainData)
trainClass = trainData[,1]
trainData= trainData[,-1]
trainData = cbind(trainData,trainClass)
head(trainData)
testClass = testData[,1]
testData = testData[,-1]
testData = cbind(testData,testClass)
head(testData)
model = naiveBayes(trainData$trainClass~., data = trainData)
model$levels
model$call
model$apriori
model$tables
head(testData[,-9])
predict(model,testData[,-9])
prediction = predict(model,testData[,-9])
prediction
model = naiveBayes(as.factor(trainData$trainClass)~., data = trainData)
prediction = predict(model,testData[,-9])
prediction
sum(prediction!=testData[,9])
sum(prediction==testData[,9])
table(predict(model,testData[,-9]),testData[,9])
testVector
testData <- dataset[testVector,]
trainData <- dataset[-testVector,]
head(trainData)
head(testData)
trainData = trainData[,-c(1,2)]
testData = testData[,-c(1,2)]
head(trainData)
head(testData)
rownames(trainData) = NULL
rownames(testData) = NULL
head(trainData)
head(testData)
model = naiveBayes(as.factor(trainData$Class)~., data = trainData)
head(testData[,1])
predictionc = predict(model,testData[,-1])
table(predict(model,testData[,-1]),testData,1)
table(predict(model,testData[,-1]),testData[,1])
accuracyTestData = read.csv("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/AccuracyTestingData/AccuracyData-2015-04-19.csv")
head(accuracyTestData)
accuracyTestData = accuracyTestData[,-c(1,2,3)]
head(accuracyTestData)
rownames(accuracyTestData) = NULL
head(accuracyTestData[,-1])
head(accuracyTestData[,1])
table(predict(model,accuracyTestData[,-1]),accuracyTestData[,1])
model.logistic = glm(as.factor(trainData$Class)~.,data=trainData,family= binomial(link="logit"))
head(testData)
table(predict(model.logistic,testData[,-1]),testData[,1])
prediction.logistic = predict(model.logistic,testData[,-1])
prediction.logistic
?glm
model.logistic = glm(trainData$Class~.,data=trainData,family= binomial(link="logit"))
model.logistic = glm(as.factor(trainData$Class)~.,data=trainData,family= binomial(link="logit"))
pred = predict(model.logistic,testData[,-1],type="probs")
pred = predict(model.logistic,testData[,-1])
pred
table(predict(model.logistic,testData[,-1]),testData[,1])
library(nnet)
model.logistic = multinom(trainData$Class~.,data=trainData)
predict(model.logistic,testData[,-1],"probs")
prediction = predict(model.logistic,testData[,-1],"probs")
prediction
prediction[1]
prediction[1,]
prediction[2,]
prediction[c(1,)2,]
prediction[c(1,2),]
sum(prediction[1,])
sum(prediction[2,])
sum(prediction[3,])
sum(prediction[5,])
max(prediction[1,])
prediction[1,]
which.max(prediction[1,])
which.max(prediction[2,])
which.max(prediction[3,])
head(prediction)
which.max(prediction[5,])
which.max(prediction[6,])
which.max(prediction[2,])
which.max(prediction[5,])
temp = which.max(prediction[5,])
temp
temp[0]
temp[1]
temp[2]
class(prediction)
prediction = data.frame(prediction)
class(prediction)
prediction
which.max(prediction[5,])
which.max(prediction[6,])
which.max(prediction[6,])[1]
which.max(prediction[6,])[2]
temp = which.max(prediction[6,])
temp
colnames(temp)
class(temp)
temp = data.frame(temp)
temp
temp[1]
temp[1,]
temp[1,1]
x = temp[1,1]
x
prediction[6,]
model
accuracyTestData = read.csv("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/AccuracyTestingData/AccuracyData-2015-12-31.csv")
accuracyTestData = accuracyTestData[,-c(1,2,3)]
head(accuracyTestData)
rownames(accuracyTestData) = NULL
head(accuracyTestData)
table(predict(model,accuracyTestData[,-1]),accuracyTestData[,1])
accuracyTestData = read.csv("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/AccuracyTestingData/AccuracyData-2016-01-16.csv")
accuracyTestData = accuracyTestData[,-c(1,2,3)]
head(accuracyTestData)
rownames(accuracyTestData) = NULL
head(accuracyTestData)
table(predict(model,accuracyTestData[,-1]),accuracyTestData[,1])
sum(predict(model,accuracyTestData[,-1])==accuracyTestData[,1])
nrow(accuracyTestData)
21/45
accuracyTestData = read.csv("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/AccuracyTestingData/AccuracyData-2015-04-19.csv")
accuracyTestData = accuracyTestData[,-c(1,2,3)]
head(accuracyTestData)
rownames(accuracyTestData) = NULL
table(predict(model,accuracyTestData[,-1]),accuracyTestData[,1])
sum(predict(model,accuracyTestData[,-1])==accuracyTestData[,1])
43/45
getwd()
setwd(""C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/Rscripts")
setwd(C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/Rscripts")
setwd("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/Rscripts")
ls
model
image1.MLCmodel = model
save(image1.MLCmodel,file="image1.MLCmodel.rda")
setwd("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/ValidationData")
library(e1071)
dataset = read.csv("ValidationData-2015-12-31.csv")
dataset = dataset[,-1]
testVector <- sample(nrow(dataset),nrow(dataset)*0.2)
testData <- dataset[testVector,]
trainData <- dataset[-testVector,]
trainData = trainData[,-c(1,2)]
testData = testData[,-c(1,2)]
rownames(trainData) = NULL
rownames(testData) = NULL
image2.MLCmodel = naiveBayes(as.factor(trainData$Class)~., data = trainData)
table(predict(image2.MLCmodel,testData[,-1]),testData[,1])
sum(predict(image2.MLCmodel,testData[,-1])!=testData[,1])
acc=err/nrow(testData)
err = sum(predict(image2.MLCmodel,testData[,-1])!=testData[,1])
acc=err/nrow(testData)
print(acc)
print(1-acc)
save(image2.MLCmodel,file = "image2.MLCmodel.rda")
accuracyTestData = read.csv("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/AccuracyTestingData/AccuracyData-2015-12-31.csv")
accuracyTestData = accuracyTestData[,-c(1,2,3)]
head(accuracyTestData)
rownames(accuracyTestData) = NULL
table(predict(image2.MLCmodel,accuracyTestData[,-1]),accuracyTestData[,1])
err = sum(predict(image2.MLCmodel,testData[,-1])!=testData[,1])
err
acc=err/nrow(testData)
print(1-acc)
