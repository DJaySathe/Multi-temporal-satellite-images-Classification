names(csvdata)
csvdata[,'row.names']
bn.gs = gs(csvdata)
csvd1 <- csvdata[,-"Proteins"]
csvd1 <- csvdata[,-c("Proteins")]
csvdata[,-"Proteins"]
csvdata[,-4]
head(csvdata[,-4])
csvd1 <- (csvdata[,-4])
bn.gs = gs(csvd1)
csvdata<-read.csv('C:/Users/Sanket Shahane/Google Drive/MS/FDS/Homework/HW5/HW45R/bn-data.csv')
head(csvdata)
bn.gs = gs(csvdata)
csvd1 = csvdata[,-1]
head(csvd1)
bn.gs = gs(csvd1)
bn.gs
plot(bn.gs)
summary(bn.gs)
bn.gs
fitted <- bn.fit(bn.gs,csvd1)
bn.gs = gs(csvd1,blacklist=c("Smoking","M.Work"))
bn.gs = gs(csvd1,blacklist=c("Smoking","M..Work"))
bn.gs
plot(bn.gs)
bn.gs = gs(csvd1,blacklist=c("M..Work","Smoking"))
plot(bn.gs)
bn.gs = gs(csvd1,blacklist=c("Smoking","M..Work"))
plot(bn.gs)
fitted <- bn.fit(bn.gs,csvd1)
cpquery(fitted,(Smoking="no"),(Pressure="<140"))
cpquery(fitted,(Smoking=="no"),(Pressure=="<140"))
cpquery(fitted,(Smoking=="no"),(Pressure==">140"))
cpquery(fitted,(Pressure==">140"),(Smoking=="no"))
cpquery(fitted,(Pressure=="<140"),(Smoking=="no"))
cpquery(fitted,(Pressure=="<140"),(Smoking=="yes"))
cpquery(fitted,(Pressure=="<140"),(Smoking=="yes",Proteins=="<3"))
cpquery(fitted,(Pressure=="<140"),(Smoking=="yes" && Proteins=="<3"))
cpquery(fitted,(Smoking="no"),(Proteins="<3"))
cpquery(fitted,(Smoking=="no"),(Proteins=="<3"))
cpquery(fitted,(Smoking="no"),(Proteins=">3"))
cpquery(fitted,(Smoking=="no"),(Proteins==">3"))
cpdist(fitted,(Smoking=="no"),(Proteins==">3"))
table(cpdist(fitted,(Smoking=="no"),(Proteins==">3")))
table(cpdist(fitted,"Smoking"",(Proteins==">3")))
table(cpdist(fitted,"Smoking,(Proteins==">3")))
table(cpdist(fitted,"Smoking,(Proteins==">3")))"
table(cpdist(fitted,"Smoking",(Proteins==">3")))"
""
table(cpdist(fitted,"Smoking",(Proteins==">3")))
table(cpdist(fitted,"Smoking",(Proteins=="<3")))
library(MASS)
twoD <- mvrnorm(200,mu=c(10,10),Sigma = matrix(c(2,1,1,2),2,2))
twoD1 <- mvrnorm(200,mu=c(60,50),Sigma = matrix(c(2,1,1,2),2,2))
totalData <- c(twoD,twoD1)
dim(twoD)
dim(totalData)
head(totalData)
totalData <- rbind(twoD,twoD1)
plot(twoD,col='red')
points(twoD1,col='red')
lines(twoD1,col='red')
plot(twoD1,col='red',xlim=c(0,100),ylim=c(0,100))
lines(twoD,col='red',xlim=c(0,100),ylim=c(0,100))
plot(totalData,col='red',xlim=c(0,100),ylim=c(0,100))
plot(totalData,col='red',xlim=c(0,80),ylim=c(0,70))
plot(totalData,col='red',xlim=c(0,70),ylim=c(0,60))
library(nortest)
ad.test(totalData)
ad.test(twoD)
ad.test(twoD1)
plot(density(twoD))
plot(kde2d(twoD))
head(twoD)
names(twoD)
names(twoD) <- c('x','y')
names(twoD)
head(twoD)
names(twoD) <- NULL
names(twoD)
plot(kde2d(twoD[,1],twoD[,2]))
ad.test(twoD)
0.8197*0.8197
ad.test(twoD1)
plot(density(twoD1))
plot(density(totalData))
twoD1 <- mvrnorm(200,mu=c(60,60),Sigma = matrix(c(2,1,1,2),2,2))
totalData <- rbind(twoD,twoD1)
plot(density(twoD1))
plot(density(twoD))
plot(density(totalData))
twoD1 <- mvrnorm(200,mu=c(60,70),Sigma = matrix(c(2,1,1,2),2,2))
twoD2 <- mvrnorm(200,mu=c(80,60),Sigma = matrix(c(2,1,1,2),2,2))
totalData <- rbind(twoD,twoD1,twoD2)
plot(twoD)
plot(density(twoD)
;
plot(density(twoD))
plot(density(twoD1))
plot(density(twoD2))
plot(density(totalData))
plot(totalData,col='red',xlim=c(0,80),ylim=c(0,70))
checkvalidity<-function(result,k){
print(k)
for (i in 1:k) {
print(i)
clusterframe <- data.frame(result$cluster)
opdata <- cbind(trialdata,clusterframe)
normtestdata <- opdata[which(opdata[,'result.cluster']==i),- length(opdata)]
normtestdata <- data.matrix(normtestdata)
normtest.result <- ad.test(normtestdata) #only need a valid normalality test
print(normtest.result$p.value)
if(normtest.result$p.value<=0.0001)
{
return(FALSE)
}
else{
print('valid cluster')
}
}
}
needtoinc = FALSE
library(nortest)
#trialdata <- data.frame(iris$Petal.Length,iris$Petal.Width)
trialdata <- iris[,-length(iris)]
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==10){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
needtoinc = FALSE
library(nortest)
#trialdata <- data.frame(iris$Petal.Length,iris$Petal.Width)
#trialdata <- iris[,-length(iris)]
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==10){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
totalData
trialdata <- totalData
class(trialdata)
trialdata <- data.frame(trialdata)
class(trialdata)
needtoinc = FALSE
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==10){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
attach(trialdata)
k=1
while(!needtoinc)
{
if(k==100){
break
}
result <- kmeans(trialdata,k)
print(result)
needtoinc <- checkvalidity(result,k)
k = k+1
}
library(ISLR)
default = Default
View(default)
write.csv(default)
write.csv(default,"C:/Users/Sanket Shahane/Desktop/Default.csv")
library(bnlearn)
csvdata<-read.csv('C:/Users/Sanket Shahane/Google Drive/MS/FDS/Homework/HW5/HW45R/bn-data.csv')
head(csvdata)
csvd1 <- csvdata[,-1]
bn.hs <- hc(csvd1)
plot(bn.hs)
fitted <- bn.fit(bn.hs,csvd1)
fitted$Smoking
fitted$Family
fitted$P..Work
fitted$M..Work
fitted$Proteins
fitted$Pressure
library(e1071)
data(HousVotes84)
data(HouseVotes84)
HouseVotes84
library(mlbench)
HouseVote84
data("HouseVotes84")
dataset <- HouseVotes84
fix(dataset)
HouseVotes84?
;;
?HouseVotes84
model <- naiveBayes(Class ~ ., data = HouseVotes84)
predict(model, HouseVotes84[1:10,-1])
predict(model, HouseVotes84[1:10,-1], type = "raw")
table(pred, HouseVotes84$Class)
pred <- predict(model, HouseVotes84[,-1])
table(pred, HouseVotes84$Class)
head(dataset)
head(dataset[,c(1,12)])
head(dataset[,c(1,12)],50)
head(dataset[which(dataset$Class=="republican"),c(1,12)],50)
sum(dataset[which(dataset$Class=="republican"),c(1,12)],50)
length(dataset[which(dataset$Class=="republican"),c(1,12)],50)
length(dataset[which(dataset$Class=="republican"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican"),c(1,12)],50)
nrow(dataset[which(dataset$Class=="republican"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" && dataset$V11=="y"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" && dataset$V11=="n"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" and dataset$V11=="n"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" & dataset$V11=="n"),c(1,12)])
nrow(dataset[which(dataset$Class=="republican" & dataset$V11=="y"),c(1,12)])
dataset[which(dataset$Class == "republiccan" & is.na(dataset$V11)),c(1,12)]
dataset[which(dataset$Class == "republiccan" & dataset$V11 == N/Q),c(1,12)]
dataset[which(dataset$Class == "republiccan" & dataset$V11 == NA),c(1,12)]
dataset[which(dataset$Class == "republican" & dataset$V11 == NA),c(1,12)]
dataset[which(dataset$Class == "republican" & is.na(dataset$V11)),c(1,12)]
model = naiveBayes(Class~.,data=dataset)
model
predict(model, HouseVotes84[1:10,-1])
table(predict(model, HouseVotes84[1:10,-1]),HouseVotes84$Class)
table(predict(model, HouseVotes84[1:10,-1]),HouseVotes84$Class[1:10])
pred <- predict(model, HouseVotes84[,-1])
table(pred, HouseVotes84$Class)
mean(pred==HouseVotes84$Class)
?sample()
set.seed(100)
sample(dataset,)
0.8*nrow(dataset)
training<-sample(dataset,0.8*nrow(dataset))
training<-sample(dataset,0.2*nrow(dataset))
training<-sample(dataset[,],0.2*nrow(dataset))
sample(dataset, size=0.8*nrow(dataset), replace = FALSE, prob = NULL)
trainingdata<-dataset[sample(nrow(dataset), size=0.8*nrow(dataset), replace = FALSE, prob = NULL)]
trainingdata<-dataset[sample(nrow(dataset), size=0.8*nrow(dataset), replace = FALSE, prob = NULL),]
testdata = dataset[-trainingdata,]
testdata = dataset[,] - trainingdata[,]
sample(dataset, size=0.8*nrow(dataset), replace = FALSE, prob = NULL)
arr <- sample(nrow(dataset), size=0.8*nrow(dataset), replace = FALSE, prob = NULL)
arr
trainingdata <- dataset[arr,]
testdata <- dataset[-arr,]
model <- naiveBayes(Class~.,trainingdata)
pred <- predict(model,testdata[,-1])
pred
table(pred,testdata$Class)
mean(pred==testdata$Class)
model.logistic <- glm(Class~.,family=binomial(link='logit'),data=trainingdata)
summary(model.logistic)
model.logistic <- glm(Class~.,family=binomial(link='logit'),data=trainingdata,control = list(maxit=50))
summary(model.logistic)
pred.training <- predict(model.logistic,trainingdata[,-1])
mean(pred.training,trainingdata$Class)
mean(pred.training,na.omit(trainingdata$Class)
)
mean(pred.training==trainingdata$Class)
mean(pred.training==na.omit(trainingdata$Class))
is.na(pred.training)
pred.training
na.omit(pred.training)
mean(na.omit(pred.training)==na.omit(trainingdata$Class))
dataset.logistic <- na.omit(dataset)
nrow(dataset.logistic)
nrow(dataset)
arr.logistic <- sample(nrow(dataset.logistic),0.8*nrow(dataset.logistic),replace = FALSE)
trainingdata.logistic = dataset.logistic[arr.logistic,]
testdata.logistic = dataset.logistic[-arr.logistic,]
model.logistic <- glm(Class~.,family=binomial(link='logit'),data=trainingdata.logistic,control = list(maxit=50))
pred.training(model.logistic,trainingdata.logistic[,-1])
pred.training <- predict(model.logistic,trainingdata.logistic[,-1])
mean(pred.training,trainingdata.logistic$Class)
mean(pred.training==trainingdata.logistic$Class)
pred.training
pred.training <- predict(model.logistic,trainingdata.logistic[,-1],type = 'response')
predict()
pred.training
pred.training <- ifelse(pred.training > 0.5,1,0)
pred.training
pred.training <- ifelse(pred.training > 0.5,'y','n')
pred.training
mean(pred.training==trainingdata.logistic$Class)
trainingdata.logistic$Class
pred.training <- ifelse(pred.training > 0.5,'democrat','republican')
mean(pred.training==trainingdata.logistic$Class)
pred.training <- predict(model.logistic,trainingdata.logistic[,-1],type = 'response')
pred.training
pred.training <- ifelse(pred.training > 0.5,'democrat','republican')
mean(pred.training==trainingdata.logistic$Class)
pred.training
pred.training <- predict(model.logistic,trainingdata.logistic[,-1],type = 'response')
pred.training <- ifelse(pred.training > 0.5,"republican","democrat")
mean(pred.training==trainingdata.logistic$Class)
fix(pred.training)
pred.training<-data.frame(pred.training)
fix(pred.training)
fix(trainingdata.logistic$Class)
fix(trainingdata.logistic)
pred.training
trainingdata.logistic$Class
pred.training$pred.training
pred.training$pred.training==trainingdata.logistic$Class
q()
# Code for saving the classifier on each image after validation.
library(e1071)
dataset = read.csv("ValidationData-2015-12-31.csv") #open the image data
dataset = dataset[,-c(1,2,3)]
# shuffle dataset for cross-validation
shuffleVec = sample(nrow(dataset),nrow(dataset))
dataset = dataset[shuffleVec,]
crossvalidationError = 0
k=10
for(i in seq(0,k-1,1)){
testVector = seq(1,nrow(dataset)%/%k)
testVector = testVector + nrow(dataset)%/%k*i
testData = dataset[testVector,]
trainData = dataset[-testVector,]
temp.model = naiveBayes(as.factor(trainData$Class)~.,data=trainData)
temp.predictions = predict(temp.model,testData[,-1])
tmp.err = sum(temp.predictions!=testData[,1])/nrow(testData)
print(table(predict(temp.model,testData[,-1]),testData[,1]))
print(tmp.err)
crossvalidationError = crossvalidationError+tmp.err
}
crossvalidationError = crossvalidationError/k
model = naiveBayes(as.factor(dataset$Class)~.,data=dataset)
#save the model and the error results rename the file according to the image
image2.MLCmodel = list(model,crossvalidationError)
save(image2.MLCmodel,file = "image2.MLCmodel.rda")
library(mlbench)
library(MASS)
data()
AirPassengers
USArrests
InsectSprays
?InsectSprays
iris
library(randomForest)
?randomForest()
head
head(iris)
rmf = randomForest(train[,-"Species"],train[,"Species"],ntree = 100)
library(randomForest)
vec = sample(nrow(iris),nrow(iris)*0.2)
train = iris[vec,]
test = iris[-vec,]
rmf = randomForest(train[,-"Species"],train[,"Species"],ntree = 100)
rmf = randomForest(train[,-c("Species")],train[,c("Species")],ntree = 100)
rmf = randomForest(train[,-5],train[,5],ntree = 100)
rmf
rmf$predicted
rmf$importance
rmf$forest
rmf
predict(rmf,test[,-5])
table(test[,5], predict(rmf,test[,-5]))
mean(test[,5] == predict(rmf,test[,-5]))
library(rpart)
?rpart()
library(tree)
dt = rpart(Species~.,train)
dt
table(test[,5],predict(dt,test[,-5]))
predict(dt,test[,-5])
table(test[,5],predict(dt,test[,-5]),type="class")
dt = rpart(Species~.,train,method="class")
dt
predict(dt,test[,-5])
table(test[,5],predict(dt,test[,-5]),type="class")
predict(dt,test[,-5],type="class")
table(test[,5],predict(dt,test[,-5],type="class"))
mean(test[,5] == predict(dt,test[,-5],type="class"))
dtm = rpart(Species~.,train,method="class")
p<-predict(dtm,test,type="class")
table(test[,5],p)
vec = sample(nrow(iris),nrow(iris)*0.2)
train = iris[vec,]
test = iris[-vec,]
library(rpart)
dtm = rpart(Species~.,train,method="class")
p<-predict(dtm,test,type="class")
table(test[,5],p)
vec = sample(nrow(iris),nrow(iris)*0.2)
train = iris[vec,]
test = iris[-vec,]
#rmf = randomForest(train[,-5],train[,5],ntree = 100)
library(rpart)
dtm = rpart(Species~.,train,method="class")
p<-predict(dtm,test,type="class")
table(test[,5],p)
vec = sample(nrow(iris),nrow(iris)*0.2)
train = iris[vec,]
test = iris[-vec,]
#rmf = randomForest(train[,-5],train[,5],ntree = 100)
library(rpart)
dtm = rpart(Species~.,train,method="class")
p<-predict(dtm,test,type="class")
table(test[,5],p)
vec = sample(nrow(iris),nrow(iris)*0.2)
train = iris[vec,]
test = iris[-vec,]
#rmf = randomForest(train[,-5],train[,5],ntree = 100)
library(rpart)
dtm = rpart(Species~.,train,method="class")
p<-predict(dtm,test,type="class")
table(test[,5],p)
vec = sample(nrow(iris),nrow(iris)*0.2)
train = iris[vec,]
test = iris[-vec,]
#rmf = randomForest(train[,-5],train[,5],ntree = 100)
library(rpart)
dtm = rpart(Species~.,train,method="class")
p<-predict(dtm,test,type="class")
table(test[,5],p)
exit
exit()
q()
setwd("C:/Users/Sanket Shahane/Google Drive/MS/ALDA/Project/Multi-Temporal-Classification/TrainingData/ValidationData")
df = read.csv('ValidationData-2015-04-19.csv')
head(df)
df = df[,-c(1,2,3)]
head(df)
vec = sample(nrow(df),nrow(df)*0.2)
train = df[vec,]
test = df[-vec,]
library(randomForest)
rmf = randomForest(train[,-1],train[,1],ntree = 100)
train = df[-vec,]
test = df[vec,]
rmf = randomForest(train[,-1],train[,1],ntree = 100)
train[,-1]
?randomForest
rmf = randomForest(Class~.,data = train,ntree = 100)
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 100)
rmf
p = predict(rmf,test[,-1])
p
table(test[,1],p)
mean(test[,1],p)
mean(test[,1]==p)
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 500)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 1000)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 10)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 20)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
df = read.csv('ValidationData-2015-12-31.csv')
df = df[,-c(1,2,3)]
vec = sample(nrow(df),nrow(df)*0.2)
train = df[-vec,]
test = df[vec,]
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 20)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
df = read.csv('ValidationData-2015-12-31.csv')
df = df[,-c(1,2,3)]
vec = sample(nrow(df),nrow(df)*0.2)
train = df[-vec,]
test = df[vec,]
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 500)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
df = read.csv('ValidationData-2016-01-16.csv')
df = df[,-c(1,2,3)]
vec = sample(nrow(df),nrow(df)*0.2)
train = df[-vec,]
test = df[vec,]
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 500)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
df = read.csv('ValidationData-2016-03-20.csv')
df = df[,-c(1,2,3)]
vec = sample(nrow(df),nrow(df)*0.2)
train = df[-vec,]
test = df[vec,]
rmf = randomForest(as.factor(Class)~.,data = train,ntree = 500)
p = predict(rmf,test[,-1])
table(test[,1],p)
mean(test[,1]==p)
